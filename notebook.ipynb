{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8384d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "#                   CSIRO BIOMASS PREDICTION – NOTEBOOK FINAL\n",
    "# ================================================================\n",
    "\n",
    "# =============================\n",
    "# 1. IMPORTS Y CONFIGURACIÓN\n",
    "# =============================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "\n",
    "# ML – tabular\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Deep Learning – CNN\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Utilidades\n",
    "from math import sqrt\n",
    "\n",
    "# =============================\n",
    "# 2. CARGA DE DATOS\n",
    "# =============================\n",
    "\n",
    "DATA_DIR = \"data/csiro-biomass\"\n",
    "train_df = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\n",
    "test_df  = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))\n",
    "\n",
    "print(\"TRAIN SHAPE:\", train_df.shape)\n",
    "print(\"TEST SHAPE:\", test_df.shape)\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5503b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# 3. EXPLORACIÓN INICIAL\n",
    "# =============================\n",
    "\n",
    "print(train_df.describe())\n",
    "print(train_df.info())\n",
    "\n",
    "# Valores faltantes\n",
    "print(\"\\nMissing values:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "# Distribución de target_name\n",
    "sns.countplot(y=train_df[\"target_name\"])\n",
    "plt.title(\"Distribución de componentes de biomasa\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d66ffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# 4. FEATURE ENGINEERING\n",
    "# =============================\n",
    "\n",
    "df = train_df.copy()\n",
    "\n",
    "# Convertir fecha a datetime\n",
    "df[\"Sampling_Date\"] = pd.to_datetime(df[\"Sampling_Date\"])\n",
    "df[\"Year\"] = df[\"Sampling_Date\"].dt.year\n",
    "df[\"Month\"] = df[\"Sampling_Date\"].dt.month\n",
    "\n",
    "# Columnas num / cat\n",
    "num_cols = [\"Pre_GSHH_NDVI\", \"Height_Ave_cm\", \"Year\", \"Month\"]\n",
    "cat_cols = [\"State\", \"Species\", \"target_name\"]\n",
    "\n",
    "X = df[num_cols + cat_cols]\n",
    "y = df[\"target\"]\n",
    "\n",
    "print(\"Numéricas:\", num_cols)\n",
    "print(\"Categóricas:\", cat_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e839f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 5. MODELO BASELINE – REGRESIÓN LINEAL\n",
    "# ================================================================\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "baseline_model = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"lr\", LinearRegression())\n",
    "])\n",
    "\n",
    "scores = cross_val_score(\n",
    "    baseline_model, X, y,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "rmse_baseline = -scores\n",
    "print(\"RMSE Baseline:\", rmse_baseline.mean(), \"+/-\", rmse_baseline.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865a9114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 6. MODELO XGBOOST – BÚSQUEDA DE HIPERPARÁMETROS\n",
    "# ================================================================\n",
    "\n",
    "xgb_pipe = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"xgb\", XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"xgb__n_estimators\": [500, 800, 900],\n",
    "    \"xgb__learning_rate\": [0.01, 0.05],\n",
    "    \"xgb__max_depth\": [4, 5],\n",
    "    \"xgb__subsample\": [0.8, 0.9],\n",
    "    \"xgb__colsample_bytree\": [0.8, 0.9],\n",
    "    \"xgb__gamma\": [0, 0.3, 0.4],\n",
    "    \"xgb__min_child_weight\": [1,3]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    xgb_pipe,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"\\nMejores hiperparámetros:\", grid.best_params_)\n",
    "print(\"Mejor RMSE:\", -grid.best_score_)\n",
    "\n",
    "model_xgb = grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f92e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 7. MODELO CNN POR COMPONENTE DE BIOMASA\n",
    "# ================================================================\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def path_full(rel_path):\n",
    "    return os.path.join(DATA_DIR, rel_path)\n",
    "\n",
    "train_df[\"full_path\"] = train_df[\"image_path\"].apply(path_full)\n",
    "\n",
    "# Entrenaremos un modelo CNN por cada tipo de biomasa\n",
    "targets = train_df[\"target_name\"].unique()\n",
    "cnn_models = {}\n",
    "\n",
    "def create_cnn():\n",
    "    model = models.Sequential([\n",
    "        layers.Rescaling(1./255, input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(128, 3, activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff1006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar 1 red por target_name\n",
    "for tname in targets:\n",
    "    print(f\"\\n=== Entrenando CNN para {tname} ===\")\n",
    "    \n",
    "    df_t = train_df[train_df[\"target_name\"] == tname].copy()\n",
    "    df_t[\"full_path\"] = df_t[\"image_path\"].apply(path_full)\n",
    "    \n",
    "    paths = df_t[\"full_path\"].values\n",
    "    labels = df_t[\"target\"].values\n",
    "\n",
    "    def load_img(path, label):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        return img / 255.0, label\n",
    "    \n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    ds = ds.map(load_img, num_parallel_calls=AUTOTUNE).batch(16).prefetch(AUTOTUNE)\n",
    "\n",
    "    model = create_cnn()\n",
    "    model.fit(ds, epochs=5, verbose=1)\n",
    "\n",
    "    cnn_models[tname] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667b50fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 8. GENERAR SUBMISSION FINAL (CNN)\n",
    "# ================================================================\n",
    "\n",
    "test_df[\"full_path\"] = test_df[\"image_path\"].apply(path_full)\n",
    "\n",
    "preds = []\n",
    "\n",
    "for tname in targets:\n",
    "    print(f\"\\n>>> Prediciendo para {tname}\")\n",
    "    df_t = test_df[test_df[\"target_name\"] == tname]\n",
    "\n",
    "    def load_test(path):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        return img / 255.0\n",
    "    \n",
    "    ds_test = tf.data.Dataset.from_tensor_slices(df_t[\"full_path\"].values)\n",
    "    ds_test = ds_test.map(load_test).batch(16)\n",
    "\n",
    "    pred = cnn_models[tname].predict(ds_test).flatten()\n",
    "    preds.extend(pred)\n",
    "\n",
    "submission_cnn = pd.DataFrame({\n",
    "    \"sample_id\": test_df[\"sample_id\"],\n",
    "    \"target\": preds\n",
    "})\n",
    "\n",
    "submission_cnn.to_csv(\"submission_cnn_per_target.csv\", index=False)\n",
    "submission_cnn.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfca14b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 9. GUARDAR SUBMISSION XGBOOST Y COMPARAR\n",
    "# ================================================================\n",
    "\n",
    "X_test_tab = test_df.drop(columns=[\"sample_id\",\"image_path\"])\n",
    "\n",
    "pred_xgb = model_xgb.predict(X_test_tab)\n",
    "\n",
    "submission_xgb = pd.DataFrame({\n",
    "    \"sample_id\": test_df[\"sample_id\"],\n",
    "    \"target\": pred_xgb\n",
    "})\n",
    "\n",
    "submission_xgb.to_csv(\"submission_model2_xgb.csv\", index=False)\n",
    "submission_xgb.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
