{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f661074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>image_path</th>\n",
       "      <th>Sampling_Date</th>\n",
       "      <th>State</th>\n",
       "      <th>Species</th>\n",
       "      <th>Pre_GSHH_NDVI</th>\n",
       "      <th>Height_Ave_cm</th>\n",
       "      <th>target_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID1011485656__Dry_Clover_g</td>\n",
       "      <td>train/ID1011485656.jpg</td>\n",
       "      <td>2015/9/4</td>\n",
       "      <td>Tas</td>\n",
       "      <td>Ryegrass_Clover</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.6667</td>\n",
       "      <td>Dry_Clover_g</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID1011485656__Dry_Dead_g</td>\n",
       "      <td>train/ID1011485656.jpg</td>\n",
       "      <td>2015/9/4</td>\n",
       "      <td>Tas</td>\n",
       "      <td>Ryegrass_Clover</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.6667</td>\n",
       "      <td>Dry_Dead_g</td>\n",
       "      <td>31.9984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID1011485656__Dry_Green_g</td>\n",
       "      <td>train/ID1011485656.jpg</td>\n",
       "      <td>2015/9/4</td>\n",
       "      <td>Tas</td>\n",
       "      <td>Ryegrass_Clover</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.6667</td>\n",
       "      <td>Dry_Green_g</td>\n",
       "      <td>16.2751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID1011485656__Dry_Total_g</td>\n",
       "      <td>train/ID1011485656.jpg</td>\n",
       "      <td>2015/9/4</td>\n",
       "      <td>Tas</td>\n",
       "      <td>Ryegrass_Clover</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.6667</td>\n",
       "      <td>Dry_Total_g</td>\n",
       "      <td>48.2735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID1011485656__GDM_g</td>\n",
       "      <td>train/ID1011485656.jpg</td>\n",
       "      <td>2015/9/4</td>\n",
       "      <td>Tas</td>\n",
       "      <td>Ryegrass_Clover</td>\n",
       "      <td>0.62</td>\n",
       "      <td>4.6667</td>\n",
       "      <td>GDM_g</td>\n",
       "      <td>16.2750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sample_id              image_path Sampling_Date State  \\\n",
       "0  ID1011485656__Dry_Clover_g  train/ID1011485656.jpg      2015/9/4   Tas   \n",
       "1    ID1011485656__Dry_Dead_g  train/ID1011485656.jpg      2015/9/4   Tas   \n",
       "2   ID1011485656__Dry_Green_g  train/ID1011485656.jpg      2015/9/4   Tas   \n",
       "3   ID1011485656__Dry_Total_g  train/ID1011485656.jpg      2015/9/4   Tas   \n",
       "4         ID1011485656__GDM_g  train/ID1011485656.jpg      2015/9/4   Tas   \n",
       "\n",
       "           Species  Pre_GSHH_NDVI  Height_Ave_cm   target_name   target  \n",
       "0  Ryegrass_Clover           0.62         4.6667  Dry_Clover_g   0.0000  \n",
       "1  Ryegrass_Clover           0.62         4.6667    Dry_Dead_g  31.9984  \n",
       "2  Ryegrass_Clover           0.62         4.6667   Dry_Green_g  16.2751  \n",
       "3  Ryegrass_Clover           0.62         4.6667   Dry_Total_g  48.2735  \n",
       "4  Ryegrass_Clover           0.62         4.6667         GDM_g  16.2750  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# üîπ Ruta base LOCAL (no Kaggle)\n",
    "BASE_DIR = \"data/csiro-biomass\"\n",
    "TRAIN_CSV = os.path.join(BASE_DIR, \"train.csv\")\n",
    "TEST_CSV  = os.path.join(BASE_DIR, \"test.csv\")\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df  = pd.read_csv(TEST_CSV)\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d537e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def build_full_path(path_series, base_dir=BASE_DIR):\n",
    "    \"\"\"\n",
    "    Convierte image_path relativo (train/xxx.jpg) en path absoluto.\n",
    "    \"\"\"\n",
    "    return path_series.apply(lambda p: os.path.join(base_dir, p))\n",
    "\n",
    "def load_image(path, label=None):\n",
    "    \"\"\"\n",
    "    Lee una imagen desde disco, la redimensiona y la normaliza.\n",
    "    Si label es None, devuelve solo la imagen (para test).\n",
    "    \"\"\"\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    img = img / 255.0\n",
    "    if label is None:\n",
    "        return img\n",
    "    return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "969b6822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def make_datasets_for_target(train_df, target_name, base_dir=BASE_DIR):\n",
    "    \"\"\"\n",
    "    Filtra train_df por un target_name y arma ds_train / ds_val.\n",
    "    \"\"\"\n",
    "    df_t = train_df[train_df[\"target_name\"] == target_name].copy()\n",
    "    \n",
    "    # Paths completos a las im√°genes\n",
    "    paths = build_full_path(df_t[\"image_path\"], base_dir=base_dir)\n",
    "    paths = paths.values  # array de strings\n",
    "    y = df_t[\"target\"].values.astype(\"float32\")\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        paths, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    ds_train = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    ds_train = ds_train.map(\n",
    "        lambda p, t: load_image(p, t),\n",
    "        num_parallel_calls=AUTOTUNE\n",
    "    ).shuffle(512).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    \n",
    "    ds_val = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "    ds_val = ds_val.map(\n",
    "        lambda p, t: load_image(p, t),\n",
    "        num_parallel_calls=AUTOTUNE\n",
    "    ).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    \n",
    "    return ds_train, ds_val, df_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0871c97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(357,\n",
       " <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.float32, name=None))>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train_ex, ds_val_ex, df_ex = make_datasets_for_target(train_df, \"Dry_Total_g\")\n",
    "len(df_ex), ds_train_ex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "713f1d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(img_size=IMG_SIZE):\n",
    "    base_model = keras.applications.EfficientNetB0(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(img_size, img_size, 3),\n",
    "        pooling=\"avg\",\n",
    "    )\n",
    "    base_model.trainable = False  # primero congelado\n",
    "\n",
    "    inputs = keras.Input(shape=(img_size, img_size, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(1, dtype=\"float32\")(x)  # regresi√≥n\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=\"mse\",\n",
    "        metrics=[keras.metrics.RootMeanSquaredError(name=\"rmse\")]\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d595427c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Epoch 1/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 2625.8274 - rmse: 51.2037 - val_loss: 1526.7179 - val_rmse: 39.0732\n",
      "Epoch 2/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 825ms/step - loss: 1739.7795 - rmse: 41.5815 - val_loss: 861.9598 - val_rmse: 29.3592\n",
      "Epoch 3/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 835ms/step - loss: 1004.5005 - rmse: 31.6664 - val_loss: 587.2973 - val_rmse: 24.2342\n",
      "Epoch 4/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 837ms/step - loss: 781.8272 - rmse: 27.8231 - val_loss: 640.0671 - val_rmse: 25.2995\n",
      "Epoch 5/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 828ms/step - loss: 808.1470 - rmse: 28.2875 - val_loss: 644.9507 - val_rmse: 25.3959\n"
     ]
    }
   ],
   "source": [
    "target_example = \"Dry_Total_g\"\n",
    "\n",
    "ds_train, ds_val, df_total = make_datasets_for_target(train_df, target_example)\n",
    "\n",
    "model_example = build_cnn_model()\n",
    "\n",
    "history = model_example.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=5,  # empieza con pocos epochs para probar\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_rmse\",\n",
    "            patience=2,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4833a330",
   "metadata": {},
   "source": [
    "## Entrenar modelo por cada componente de biomasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d34dbb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Entrenando modelo para Dry_Clover_g =====\n",
      "Epoch 1/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 156.9745 - rmse: 12.3663 - val_loss: 177.9947 - val_rmse: 13.3415\n",
      "Epoch 2/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 848ms/step - loss: 152.5043 - rmse: 12.3090 - val_loss: 181.8421 - val_rmse: 13.4849\n",
      "Epoch 3/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 873ms/step - loss: 138.8971 - rmse: 11.7774 - val_loss: 184.0837 - val_rmse: 13.5677\n",
      "Modelo para Dry_Clover_g guardado en model_Dry_Clover_g.keras\n",
      "\n",
      "===== Entrenando modelo para Dry_Dead_g =====\n",
      "Epoch 1/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 258.2769 - rmse: 16.0060 - val_loss: 146.6577 - val_rmse: 12.1102\n",
      "Epoch 2/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 825ms/step - loss: 141.8284 - rmse: 11.8788 - val_loss: 153.9571 - val_rmse: 12.4079\n",
      "Epoch 3/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 824ms/step - loss: 178.4174 - rmse: 13.3466 - val_loss: 145.0118 - val_rmse: 12.0421\n",
      "Epoch 4/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 827ms/step - loss: 195.6644 - rmse: 13.8821 - val_loss: 146.4405 - val_rmse: 12.1013\n",
      "Epoch 5/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 841ms/step - loss: 144.0198 - rmse: 11.9795 - val_loss: 145.8681 - val_rmse: 12.0776\n",
      "Modelo para Dry_Dead_g guardado en model_Dry_Dead_g.keras\n",
      "\n",
      "===== Entrenando modelo para Dry_Green_g =====\n",
      "Epoch 1/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1s/step - loss: 1448.3768 - rmse: 37.9507 - val_loss: 613.6583 - val_rmse: 24.7721\n",
      "Epoch 2/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 831ms/step - loss: 750.3633 - rmse: 27.3413 - val_loss: 471.6417 - val_rmse: 21.7173\n",
      "Epoch 3/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 815ms/step - loss: 642.3279 - rmse: 25.2926 - val_loss: 543.7449 - val_rmse: 23.3183\n",
      "Epoch 4/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 830ms/step - loss: 889.9658 - rmse: 29.6677 - val_loss: 555.2950 - val_rmse: 23.5647\n",
      "Modelo para Dry_Green_g guardado en model_Dry_Green_g.keras\n",
      "\n",
      "===== Entrenando modelo para Dry_Total_g =====\n",
      "Epoch 1/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 2575.3398 - rmse: 50.6899 - val_loss: 1461.7280 - val_rmse: 38.2326\n",
      "Epoch 2/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 828ms/step - loss: 1589.9712 - rmse: 39.8097 - val_loss: 783.7345 - val_rmse: 27.9953\n",
      "Epoch 3/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 827ms/step - loss: 922.0760 - rmse: 30.2799 - val_loss: 585.1667 - val_rmse: 24.1902\n",
      "Epoch 4/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 816ms/step - loss: 798.1938 - rmse: 28.2124 - val_loss: 666.3867 - val_rmse: 25.8145\n",
      "Epoch 5/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 829ms/step - loss: 966.1818 - rmse: 31.0612 - val_loss: 626.1780 - val_rmse: 25.0235\n",
      "Modelo para Dry_Total_g guardado en model_Dry_Total_g.keras\n",
      "\n",
      "===== Entrenando modelo para GDM_g =====\n",
      "Epoch 1/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1s/step - loss: 1549.9551 - rmse: 39.2852 - val_loss: 829.1486 - val_rmse: 28.7949\n",
      "Epoch 2/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 833ms/step - loss: 985.0679 - rmse: 31.3557 - val_loss: 500.1406 - val_rmse: 22.3638\n",
      "Epoch 3/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 850ms/step - loss: 538.1771 - rmse: 23.0709 - val_loss: 518.0172 - val_rmse: 22.7600\n",
      "Epoch 4/5\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 833ms/step - loss: 686.0609 - rmse: 26.1744 - val_loss: 538.3034 - val_rmse: 23.2014\n",
      "Modelo para GDM_g guardado en model_GDM_g.keras\n"
     ]
    }
   ],
   "source": [
    "TARGETS = [\"Dry_Clover_g\", \"Dry_Dead_g\", \"Dry_Green_g\", \"Dry_Total_g\", \"GDM_g\"]\n",
    "\n",
    "models = {}\n",
    "\n",
    "for tn in TARGETS:\n",
    "    print(f\"\\n===== Entrenando modelo para {tn} =====\")\n",
    "    ds_train, ds_val, df_t = make_datasets_for_target(train_df, tn)\n",
    "\n",
    "    model = build_cnn_model()\n",
    "\n",
    "    history = model.fit(\n",
    "        ds_train,\n",
    "        validation_data=ds_val,\n",
    "        epochs=5,  # si ves que va bien y tienes tiempo, puedes subir a 8‚Äì10\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_rmse\",\n",
    "                patience=2,\n",
    "                restore_best_weights=True\n",
    "            )\n",
    "        ],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Guardamos el modelo en memoria\n",
    "    models[tn] = model\n",
    "\n",
    "    # Opcional: guardar a disco por si quieres reusar luego\n",
    "    model_path = f\"model_{tn}.keras\"\n",
    "    model.save(model_path)\n",
    "    print(f\"Modelo para {tn} guardado en {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91a88bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Prediciendo para Dry_Clover_g\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\n",
      ">>> Prediciendo para Dry_Dead_g\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\n",
      ">>> Prediciendo para Dry_Green_g\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\n",
      ">>> Prediciendo para Dry_Total_g\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\n",
      ">>> Prediciendo para GDM_g\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000214E39DFE20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID1001187975__Dry_Clover_g</td>\n",
       "      <td>7.893603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID1001187975__Dry_Dead_g</td>\n",
       "      <td>12.304406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID1001187975__Dry_Green_g</td>\n",
       "      <td>22.664375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID1001187975__Dry_Total_g</td>\n",
       "      <td>44.478161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID1001187975__GDM_g</td>\n",
       "      <td>26.902075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sample_id     target\n",
       "0  ID1001187975__Dry_Clover_g   7.893603\n",
       "1    ID1001187975__Dry_Dead_g  12.304406\n",
       "2   ID1001187975__Dry_Green_g  22.664375\n",
       "3   ID1001187975__Dry_Total_g  44.478161\n",
       "4         ID1001187975__GDM_g  26.902075"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = []\n",
    "\n",
    "for tn in TARGETS:\n",
    "    print(f\"\\n>>> Prediciendo para {tn}\")\n",
    "    df_tst = test_df[test_df[\"target_name\"] == tn].copy()\n",
    "    if df_tst.empty:\n",
    "        print(f\"  No hay filas en test para {tn}, se omite.\")\n",
    "        continue\n",
    "\n",
    "    paths_tst = build_full_path(df_tst[\"image_path\"], base_dir=BASE_DIR)\n",
    "    paths_tst = paths_tst.values\n",
    "\n",
    "    ds_tst = tf.data.Dataset.from_tensor_slices(paths_tst)\n",
    "    ds_tst = ds_tst.map(load_image, num_parallel_calls=AUTOTUNE)\n",
    "    ds_tst = ds_tst.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "    y_pred_tn = models[tn].predict(ds_tst).reshape(-1)\n",
    "    df_tst[\"target\"] = y_pred_tn\n",
    "\n",
    "    preds.append(df_tst[[\"sample_id\", \"target\"]])\n",
    "\n",
    "submission_cnn = pd.concat(preds, axis=0).sort_values(\"sample_id\")\n",
    "submission_cnn.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69fc0b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ submission_cnn_per_target.csv generado.\n"
     ]
    }
   ],
   "source": [
    "submission_cnn.to_csv(\"submission_cnn_per_target.csv\", index=False)\n",
    "print(\"‚úÖ submission_cnn_per_target.csv generado.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
